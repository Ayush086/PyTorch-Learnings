{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b9ea57",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:21.193323Z",
     "iopub.status.busy": "2026-01-25T10:42:21.193014Z",
     "iopub.status.idle": "2026-01-25T10:42:22.159330Z",
     "shell.execute_reply": "2026-01-25T10:42:22.158189Z"
    },
    "papermill": {
     "duration": 0.974248,
     "end_time": "2026-01-25T10:42:22.161429",
     "exception": false,
     "start_time": "2026-01-25T10:42:21.187181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/unique-qa-dataset/100_Unique_QA_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d389dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:22.170612Z",
     "iopub.status.busy": "2026-01-25T10:42:22.169686Z",
     "iopub.status.idle": "2026-01-25T10:42:22.207183Z",
     "shell.execute_reply": "2026-01-25T10:42:22.206351Z"
    },
    "papermill": {
     "duration": 0.044056,
     "end_time": "2026-01-25T10:42:22.208929",
     "exception": false,
     "start_time": "2026-01-25T10:42:22.164873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/unique-qa-dataset/100_Unique_QA_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b66ae11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:22.216967Z",
     "iopub.status.busy": "2026-01-25T10:42:22.216420Z",
     "iopub.status.idle": "2026-01-25T10:42:22.222611Z",
     "shell.execute_reply": "2026-01-25T10:42:22.221963Z"
    },
    "papermill": {
     "duration": 0.011879,
     "end_time": "2026-01-25T10:42:22.224115",
     "exception": false,
     "start_time": "2026-01-25T10:42:22.212236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'the', 'capital', 'of', 'france']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization\n",
    "def tokenize(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace('?','')\n",
    "    s = s.replace(\"'\", \"\")\n",
    "    return s.split()\n",
    "\n",
    "tokenize(df['question'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11028ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:22.231646Z",
     "iopub.status.busy": "2026-01-25T10:42:22.231385Z",
     "iopub.status.idle": "2026-01-25T10:42:22.236137Z",
     "shell.execute_reply": "2026-01-25T10:42:22.235202Z"
    },
    "papermill": {
     "duration": 0.010412,
     "end_time": "2026-01-25T10:42:22.237776",
     "exception": false,
     "start_time": "2026-01-25T10:42:22.227364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build vocab\n",
    "vocabulary = {\"<UNK>\": 0}\n",
    "\n",
    "def build_vocab(row):\n",
    "    tokenized_que = tokenize(row['question'])\n",
    "    tokenized_ans = tokenize(row['answer'])\n",
    "\n",
    "    merged_token = tokenized_que + tokenized_ans\n",
    "\n",
    "    for token in merged_token:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary[token] = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c24900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:22.245354Z",
     "iopub.status.busy": "2026-01-25T10:42:22.245085Z",
     "iopub.status.idle": "2026-01-25T10:42:22.252844Z",
     "shell.execute_reply": "2026-01-25T10:42:22.252023Z"
    },
    "papermill": {
     "duration": 0.013534,
     "end_time": "2026-01-25T10:42:22.254511",
     "exception": false,
     "start_time": "2026-01-25T10:42:22.240977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074535c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:22.262373Z",
     "iopub.status.busy": "2026-01-25T10:42:22.262110Z",
     "iopub.status.idle": "2026-01-25T10:42:22.266585Z",
     "shell.execute_reply": "2026-01-25T10:42:22.265826Z"
    },
    "papermill": {
     "duration": 0.01045,
     "end_time": "2026-01-25T10:42:22.268387",
     "exception": false,
     "start_time": "2026-01-25T10:42:22.257937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# indexing\n",
    "def text_to_indices(text, vocabulary):\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "        if token in vocabulary:\n",
    "            indexed_text.append(vocabulary[token])\n",
    "        else:\n",
    "            indexed_text.append(vocabulary['<UNK>'])\n",
    "    return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bfe5876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:22.276426Z",
     "iopub.status.busy": "2026-01-25T10:42:22.276150Z",
     "iopub.status.idle": "2026-01-25T10:42:26.177457Z",
     "shell.execute_reply": "2026-01-25T10:42:26.176735Z"
    },
    "papermill": {
     "duration": 3.907643,
     "end_time": "2026-01-25T10:42:26.179355",
     "exception": false,
     "start_time": "2026-01-25T10:42:22.271712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx_que = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
    "        idx_ans = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
    "\n",
    "        return torch.tensor(idx_que), torch.tensor(idx_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859a6e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.187951Z",
     "iopub.status.busy": "2026-01-25T10:42:26.187520Z",
     "iopub.status.idle": "2026-01-25T10:42:26.191373Z",
     "shell.execute_reply": "2026-01-25T10:42:26.190600Z"
    },
    "papermill": {
     "duration": 0.009901,
     "end_time": "2026-01-25T10:42:26.192963",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.183062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26230a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.201048Z",
     "iopub.status.busy": "2026-01-25T10:42:26.200559Z",
     "iopub.status.idle": "2026-01-25T10:42:26.243032Z",
     "shell.execute_reply": "2026-01-25T10:42:26.242121Z"
    },
    "papermill": {
     "duration": 0.048447,
     "end_time": "2026-01-25T10:42:26.244745",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.196298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 8]), tensor([9]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db06e4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.253169Z",
     "iopub.status.busy": "2026-01-25T10:42:26.252864Z",
     "iopub.status.idle": "2026-01-25T10:42:26.320445Z",
     "shell.execute_reply": "2026-01-25T10:42:26.319338Z"
    },
    "papermill": {
     "duration": 0.07462,
     "end_time": "2026-01-25T10:42:26.322892",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.248272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
      "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
      "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
      "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
      "tensor([[10, 75, 76]]) tensor([[77]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for question, answer in dataloader:\n",
    "    print(question, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575835e2",
   "metadata": {
    "papermill": {
     "duration": 0.003508,
     "end_time": "2026-01-25T10:42:26.330130",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.326622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Architecture\n",
    "\n",
    "input layer (50N) ---> hidden layer (feedback loop) (64N) ---> output layer (324N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d38b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.338710Z",
     "iopub.status.busy": "2026-01-25T10:42:26.338119Z",
     "iopub.status.idle": "2026-01-25T10:42:26.344072Z",
     "shell.execute_reply": "2026-01-25T10:42:26.343225Z"
    },
    "papermill": {
     "duration": 0.012015,
     "end_time": "2026-01-25T10:42:26.345707",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.333692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# can't use sequential container as RNN contains the feedback loop\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim = 50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "    def forward(self, question):\n",
    "        embedded_que = self.embedding(question)\n",
    "        hidden_state, final_state = self.rnn(embedded_que)\n",
    "        output = self.fc(final_state.squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57890d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.354253Z",
     "iopub.status.busy": "2026-01-25T10:42:26.353542Z",
     "iopub.status.idle": "2026-01-25T10:42:26.404561Z",
     "shell.execute_reply": "2026-01-25T10:42:26.403149Z"
    },
    "papermill": {
     "duration": 0.057315,
     "end_time": "2026-01-25T10:42:26.406464",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.349149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sending to Embedding layer\n",
      "shape of a:  torch.Size([1, 6])\n",
      "\n",
      "After sending to Embedding layer\n",
      "shape of b:  torch.Size([1, 6, 50])\n",
      "\n",
      " Intermidiate hidden states\n",
      "shape of c:  torch.Size([1, 6, 64])\n",
      "\n",
      " Final output state\n",
      "shape of d:  torch.Size([1, 1, 64])\n",
      "\n",
      " probabilities\n",
      "shape of e:  torch.Size([1, 324])\n"
     ]
    }
   ],
   "source": [
    "# architecture debug\n",
    "\n",
    "x = nn.Embedding(324, embedding_dim=50)\n",
    "y = nn.RNN(50, 64, batch_first=True) # indicating first dim will be the batch size (ie.,1)\n",
    "z = nn.Linear(64, 324)\n",
    "\n",
    "a = dataset[0][0].reshape(1,6)\n",
    "print(\"Before sending to Embedding layer\\nshape of a: \", a.shape)\n",
    "b = x(a)\n",
    "print(\"\\nAfter sending to Embedding layer\\nshape of b: \", b.shape)\n",
    "c, d = y(b)\n",
    "print('\\n Intermidiate hidden states\\nshape of c: ', c.shape)\n",
    "print('\\n Final output state\\nshape of d: ', d.shape)\n",
    "\n",
    "e = z(d.squeeze(0))\n",
    "print('\\n probabilities\\nshape of e: ', e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4172c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.415146Z",
     "iopub.status.busy": "2026-01-25T10:42:26.414854Z",
     "iopub.status.idle": "2026-01-25T10:42:26.418472Z",
     "shell.execute_reply": "2026-01-25T10:42:26.417764Z"
    },
    "papermill": {
     "duration": 0.009707,
     "end_time": "2026-01-25T10:42:26.419968",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.410261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff91203b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:26.429152Z",
     "iopub.status.busy": "2026-01-25T10:42:26.428893Z",
     "iopub.status.idle": "2026-01-25T10:42:31.785093Z",
     "shell.execute_reply": "2026-01-25T10:42:31.784380Z"
    },
    "papermill": {
     "duration": 5.362634,
     "end_time": "2026-01-25T10:42:31.787048",
     "exception": false,
     "start_time": "2026-01-25T10:42:26.424414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocabulary))\n",
    "\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58507d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:31.795951Z",
     "iopub.status.busy": "2026-01-25T10:42:31.795463Z",
     "iopub.status.idle": "2026-01-25T10:42:35.721333Z",
     "shell.execute_reply": "2026-01-25T10:42:35.720231Z"
    },
    "papermill": {
     "duration": 3.932363,
     "end_time": "2026-01-25T10:42:35.723099",
     "exception": false,
     "start_time": "2026-01-25T10:42:31.790736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 520.952395\n",
      "Epoch: 2, Loss: 452.768232\n",
      "Epoch: 3, Loss: 375.116854\n",
      "Epoch: 4, Loss: 310.436860\n",
      "Epoch: 5, Loss: 257.495051\n",
      "Epoch: 6, Loss: 209.023701\n",
      "Epoch: 7, Loss: 165.199552\n",
      "Epoch: 8, Loss: 127.763757\n",
      "Epoch: 9, Loss: 97.596924\n",
      "Epoch: 10, Loss: 74.569146\n",
      "Epoch: 11, Loss: 57.970388\n",
      "Epoch: 12, Loss: 45.692397\n",
      "Epoch: 13, Loss: 36.641284\n",
      "Epoch: 14, Loss: 29.997220\n",
      "Epoch: 15, Loss: 24.905350\n",
      "Epoch: 16, Loss: 20.962511\n",
      "Epoch: 17, Loss: 17.730291\n",
      "Epoch: 18, Loss: 15.193464\n",
      "Epoch: 19, Loss: 12.999302\n",
      "Epoch: 20, Loss: 11.334754\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for question, answer in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(question)\n",
    "        # need to calculate the numerical ans as we get the prob now\n",
    "        loss = lossFunction(pred, answer[0])\n",
    "\n",
    "        loss.backward() # calc. grads\n",
    "        optimizer.step() # update grads\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0599715d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:35.733012Z",
     "iopub.status.busy": "2026-01-25T10:42:35.732451Z",
     "iopub.status.idle": "2026-01-25T10:42:35.738012Z",
     "shell.execute_reply": "2026-01-25T10:42:35.737159Z"
    },
    "papermill": {
     "duration": 0.01236,
     "end_time": "2026-01-25T10:42:35.739650",
     "exception": false,
     "start_time": "2026-01-25T10:42:35.727290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, question, threshold=0.5):\n",
    "    # convert question text to vector\n",
    "    vector = text_to_indices(question, vocabulary)\n",
    "    ques_tensor = torch.tensor(vector).unsqueeze(0)\n",
    "\n",
    "    output = model(ques_tensor)\n",
    "    # convert logits to probs\n",
    "    probs = nn.functional.softmax(output, dim=1)\n",
    "    # find max prob\n",
    "    max_val, idx = torch.max(probs, dim=1)\n",
    "\n",
    "    if max_val < threshold:\n",
    "        print(\"I don't know\")\n",
    "\n",
    "    output = list(vocabulary.keys())[idx]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aafd28a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:42:35.749201Z",
     "iopub.status.busy": "2026-01-25T10:42:35.748677Z",
     "iopub.status.idle": "2026-01-25T10:42:35.759585Z",
     "shell.execute_reply": "2026-01-25T10:42:35.758607Z"
    },
    "papermill": {
     "duration": 0.017638,
     "end_time": "2026-01-25T10:42:35.761343",
     "exception": false,
     "start_time": "2026-01-25T10:42:35.743705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "au\n"
     ]
    }
   ],
   "source": [
    "predict(model, 'What is the chemical symbol for gold?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fda800",
   "metadata": {
    "papermill": {
     "duration": 0.003912,
     "end_time": "2026-01-25T10:42:35.769482",
     "exception": false,
     "start_time": "2026-01-25T10:42:35.765570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9332640,
     "sourceId": 14610832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.13193,
   "end_time": "2026-01-25T10:42:37.495553",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-25T10:42:18.363623",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
